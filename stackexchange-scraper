#!/bin/bash
# by Dominik Stanis≈Çaw Suchora <suchora.dominik7@gmail.com>
# License: GNU GPLv3

shopt -s extglob

declare url delay='0.5' maxprocs='3' first='1' random='1' last

IFS=$'\n'

ucurl() {
    curl -L -g -s --user-agent 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) QtWebEngine/5.15.2 Chrome/87.0.4280.144 Safari/537.36' -H 'Accept-Encoding: gzip, deflate' --compressed "$@"
}

get_posts() {
    tr -d '\r\n\t\a\f' | reliq '
        .posts div .post-layout; {
            .rating.i div .js-vote-count data-value | "%(data-value)v",
            .date div .user-info m@v>"edited"; span .relativetime | "%(title)v",
            .edited div .user-info m@"edited"; span .relativetime | "%(title)v",

            .author div .user-info m@v>"edited"; div .user-details; {
                .name [0] * l@[1] c@[0] | "%i\n",
                .reputation.u span .reputation-score | "%i"tr ",",
                .gbadge.u span title=w>gold; span .badgecount | "%i",
                .sbadge.u span title=w>silver; span .badgecount | "%i",
                .bbadge.u span title=w>bronze; span .badgecount | "%i"
            },

            .editor div .user-info m@"edited"; div .user-details; {
                .name [0] * l@[1] c@[0] | "%i",
                .reputation.u span .reputation-score | "%i\n" tr ",",
                .gbadge.u span title=w>gold; span .badgecount | "%i",
                .sbadge.u span title=w>silver; span .badgecount | "%i",
                .bbadge.u span title=w>bronze; span .badgecount | "%i"
            },

            .content div class="s-prose js-post-body" | "%i",

            .comments li #E>comment-[0-9]+; {
                .score.u div .comment-score; * c@[0] | "%i",
                .content span .comment-copy | "%i",
                .date span .comment-date; span title | "%(title)v" / sed "s/, L.*//",
                .author div; [0] a | "%i",
                .reputation.u a title | "%(title)v\n" / tr "0-9" "" "c"
            } |
        } |
    '
}

get_page() {
    local -r rh="${1#*/questions/}"
    local -r name="${rh%%/*}"
    [ -e "$name" ] && return
    echo "$1" >&2
    local -r t="$(ucurl "$1")"
    local _tmp1

    {
    reliq '
        .title h1 itemprop="name"; a | "%i\n",
        .views.u div class="flex--item ws-nowrap mb8" | "%(title)v\n" / tr "0-9" "" "c",
        .asked div class="flex--item ws-nowrap mr16 mb8" m@"Asked"; time itemprop="dateCreated" datetime | "%(datetime)v",
        .bookmarks div class="js-bookmark-count mt4" | "%(data-value)v",
        .tags.a div .ps-relative; a .post-tag | "%i\n"
    ' <<< "$t"
    get_posts <<< "$t"
    for n in $(reliq 'div .pager-answers [0]; a rel="" href | "'"$url"'%(href)v\n"' <<< "$t")
    do
        echo "$n" >&2
        ucurl "$n" | get_posts
    done
    } | jq -srcM --arg 'link' "$1" '{"link":$link}+.[0]+{"posts":(.[1:] | map(.posts[]))}' > "$name"
    sleep "$delay" "$((RANDOM%random))"
}

get_question_list() {
    local g t l
    g="$first"
    t="$(ucurl "$1?tab=newest&pagesize=50&page=$g")"
    l="$(reliq 'a class="s-pagination--item js-pagination-item" m@B>"^[0-9][0-9]*$" | "%i\n"' <<< "$t" | tail -n1)"
    [ -z "$last" ] && last="$l"
    [ "$last" -gt "$l" ] && last="$l"
    echo "$last" >&2
    while :
    do
        #[ -z "$(reliq 'a class="s-pagination--item js-pagination-item" rel="next"' <<< "$t")" ] && break
        for i in $(reliq 'a .s-link href=a>/questions/ | "'"$url"'%(href)v\n"' <<< "$t")
        do
            [ "$(jobs | wc -l)" -gt "$maxprocs" ] && wait %%
            get_page "$i" &
        done
        wait

        #echo "$links" | parallel -j "$maxprocs" 'get_page {}'

        ((g++))
        [ "$g" -gt "$last" ] && break
        sleep "$delay" "$((RANDOM%random))"
        echo "$1?tab=newest&pagesize=50&page=$g" >&2
        t="$(ucurl "$1?tab=newest&pagesize=50&page=$g")"
    done
}

get_tags() {
    local g t l
    g="$first"
    t="$(ucurl "$1?tab=populart&pagesize=50&page=$g")"
    l="$(reliq 'a class="s-pagination--item js-pagination-item" m@B>"^[0-9][0-9]*$" | "%i\n"' <<< "$t" | tail -n1)"
    [ -z "$last" ] && last="$l"
    [ "$last" -gt "$l" ] && last="$l"
    echo "$last" >&2
    while :
    do
        for c in $(reliq 'a .post-tag href | "'"$url"'%(href)v\n"' <<< "$t")
        do
            echo "$c" >&2
            get_question_list "$c"
        done
        ((g++))
        [ "$g" -gt "$last" ] && break
        sleep "$delay" "$((RANDOM%random))"
        echo "$1?tab=newest&pagesize=50&page=$g" >&2
        t="$(ucurl "$1?tab=popular&pagesize=50&page=$g")"
    done
}

usage() {
    printf '%s [OPTION]... [DIR] [URL]...\n\n' "${0##*/}"
    printf 'Options:\n  -d,\t--delay DELAY\tset delay in sleep format, by default 0.5 seconds\n'
    printf '  -r,\t--random NUM\tset number of randomness which will be added to delay, must be integer\n'
    printf '  -p,\t--max-procs NUM\tset number of processes to run at a time, by default set to 3\n'
    printf '  -f,\t--first NUM\tset first page\n'
    printf '  -l,\t--last NUM\tset last page\n'
    printf '  -h,\t--help\t\tshow this message\n\n'
    printf 'Note that options ought to be specified before the directory.\n'
}

#export -f ucurl get_page
#export PARALLEL_SHELL="$(type -p 'bash')"

while [ "$#" -gt 0 ]
do
    case "$1" in
        -d|--delay) delay="$2"; shift;;
        -r|--random) random="$2"; random="$((random+1))"; shift;;
        -p|--max-procs) maxprocs="$2"; shift;;
        -f|--first) first="$2"; shift;;
        -l|--last) last="$2"; shift;;
        -h|--help) usage >&2; exit;;
        -*) usage >&2; exit 1;;
        *) break;;
    esac
    shift
done

[ -n "$last" ] && [ "$first" -gt "$last" ] && exit 0;

[ "$#" -eq 0 ] && { usage >&2; exit 1; }
cd "$1" || { usage >&2; exit 1; }
shift

while [ "$#" -gt 0 ]
do
    url="$(sed -E 's/(http[s]:\/\/([[:alnum:]]+\.)+[[:alpha:]]+).*/\1/' <<< "$1")"
    case "$1" in
        http?(s)://+(+([[:alnum:]]).)+([[:alpha:]])/questions/tagged/+([[:alnum:]-])?(\?*))
            get_question_list "${1%%\?*}";;
        http?(s)://+(+([[:alnum:]]).)+([[:alpha:]])?([/]?(questions?(\?*))))
            get_question_list "$url/questions";;
        http?(s)://+(+([[:alnum:]]).)+([[:alpha:]])/questions/+([[:digit:]])?([/]?(*)))
            get_page "$1";;
        http?(s)://+(+([[:alnum:]]).)+([[:alpha:]])?([/]?(tags?(\?*))))
            get_tags "$url/tags";;
    esac
    shift
done
